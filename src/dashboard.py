import streamlit as st
import yaml
import json
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

from dataprep import (
    load_and_process_data,
    return_questions_from_one_question
    )

st.set_page_config(page_title="C√¢mara dos Deputados", layout="centered")

tab1, tab2, tab3 = st.tabs(["Overview", "Despesas", "Proposi√ß√µes"])

with tab1:
    st.title("C√¢mara dos Deputados")
    
    # Carregar arquivo YAML
    with open("../data/config.yaml", "r", encoding="utf-8") as file:
        config = yaml.safe_load(file)
    
    # Exibir texto sumarizado
    st.write(config["overview_summary"])
    
    # Exibir gr√°fico
    st.image("../docs/distribuicao_deputados.png", use_container_width=True)
    
    # Carregar e exibir insights
    with open("../data/insights_distribuicao_deputados.json", "r", encoding="utf-8") as file:
        insights_data = json.load(file)
        
    for insight in insights_data["insights"]:
        st.subheader(insight["topic"])
        st.write(insight["analysis"])

with tab2:
    st.title("Despesas dos Deputados")
    
    # Carregar e exibir insights sobre despesas
    with open("../data/insights_despesas_deputados.json", "r", encoding="utf-8") as file:
        insights_despesas = json.load(file)
    
    for insight in insights_despesas["insights"]:
        st.subheader(insight["Topic"])
        st.write(insight["Insight"])
    
    # Carregar dados dos deputados e criar selectbox
    df_deputados = pd.read_parquet("../data/deputados.parquet")
    deputado_selecionado = st.selectbox(
        "Selecione um deputado:",
        options=list(zip(df_deputados['id'], df_deputados['nome'])),
        format_func=lambda x: x[1]
    )
    
    # Carregar e plotar s√©rie temporal de despesas
    df_despesas = pd.read_parquet("../data/serie_despesas_di√°rias_deputados.parquet")
    
    # Filtrar dados do deputado selecionado
    df_desp_deputado = df_despesas[df_despesas['id'] == deputado_selecionado[0]]
    
    # Criar gr√°fico
    plt.figure(figsize=(12, 6))
    sns.barplot(data=df_desp_deputado, x='dia', y='valorLiquido', hue='tipo_despesa')
    plt.title(f'Despesas do Deputado {deputado_selecionado[1]}')
    plt.xlabel('Data')
    plt.ylabel('Valor (R$)')
    plt.xticks(rotation=90)
    plt.grid(True)
    plt.tight_layout()
    
    # Exibir gr√°fico no Streamlit
    st.pyplot(plt)

with tab3:
    st.title("Proposi√ß√µes")
    
    
    
            
    
    # perguntas = ['Qual √© o partido pol√≠tico com mais deputados na c√¢mara?',
    #             'Qual √© o deputado com mais despesas na c√¢mara?',
    #             'Qual √© o tipo de despesa mais declarada pelos deputados da c√¢mara?',
    #             'Quais s√£o as informa√ß√µes mais relevantes sobre as proposi√ß√µes que falam de Economia?',
    #             "Quais s√£o as informa√ß√µes mais relevantes sobre as proposi√ß√µes que falam de 'Ci√™ncia, Tecnologia e Inova√ß√£o'?"
    #             ]
    # # st.write(perguntas)
    # if 'messages' not in st.session_state:
    #     st.session_state.messages = []
    # messages = st.container(height=300)
    
    # def atualizar_mensagens(messages):
    #     # Cont√™iner para exibir mensagens
    #     with messages:
    #         for message in st.session_state.messages:
    #             with st.chat_message(message["role"]):
    #                 st.markdown(message["content"])
    
    # def gerar_resposta(prompt):
    #     import time
    #     time.sleep(2)
    #     return 'Voc√™ disse: '+ prompt
    
    # if prompt := st.chat_input("Escreva sua pergunta:"):
        
    #     atualizar_mensagens(messages)
        
    #     with messages.chat_message("user"):
    #         st.markdown(prompt)
            
    #     response = gerar_resposta(prompt)
        
    #     with messages.chat_message("assistant"):
    #         st.markdown(response)
            
    #     st.session_state.messages.append({"role": "user", "content": prompt})
    #     st.session_state.messages.append({"role": "assistant", "content": response})
        
        
        
    # st.title('\n')
    # st.title('\n')
    # st.title('\n')
    # st.title('\n')
        
        
        
        
        
        
        
        
        
        
    
    # parquet_path = '../data/df_informations.parquet'
    # # model_name = 'neuralmind/bert-base-portuguese-cased'
    # model_name = 'all-MiniLM-L6-v2'
    # llm_model_dir = '../data/bertimbau/'
    # k = 20 # n√∫mero de resultados mais pr√≥ximos
    # candidate_count = 5 # n√∫mero de respostas geradas pelo Gemini Flash
    

    # perguntas = ['Qual √© o partido pol√≠tico com mais deputados na c√¢mara?',
    #             'Qual √© o deputado com mais despesas na c√¢mara?',
    #             'Qual √© o tipo de despesa mais declarada pelos deputados da c√¢mara?',
    #             'Quais s√£o as informa√ß√µes mais relevantes sobre as proposi√ß√µes que falam de Economia?',
    #             "Quais s√£o as informa√ß√µes mais relevantes sobre as proposi√ß√µes que falam de 'Ci√™ncia, Tecnologia e Inova√ß√£o'?"
    #             ]
    
    # question = st.selectbox('Escolha uma pergunta:', perguntas, index=0)   
    # if st.button('Buscar Resposta'):
    #     if 'index' not in st.session_state or 'texts' not in st.session_state or 'embedding_model' not in st.session_state:
    #         try:
    #             with st.status('Criando Base de dados...', expanded=True) as status:
    #                 texts, index, embedding_model = load_and_process_data(parquet_path, model_name, llm_model_dir)
    #                 st.session_state['texts'] = texts
    #                 st.session_state['index'] = index
    #                 st.session_state['embedding_model'] = embedding_model
    #                 status.update(
    #                 label="Base de Dados criada com sucesso!", state="complete", expanded=False
    #             )
    #         except Exception as e:
    #             print(f'################# Erro ao carregar e processar os dados {e}')
    #     else:
    #         texts = st.session_state['texts']
    #         index = st.session_state['index']
    #         embedding_model = st.session_state['embedding_model']
    #         st.toast("Index carregado com sucesso!")

    #     try:
    #         with st.status('Obtendo Resposta...', expanded=True) as status:
    #             questions, question_answers, response, responses, traducao = return_questions_from_one_question(question, texts, index, embedding_model, k, candidate_count)
    #             st.session_state['resposta'] = traducao 
    #             status.update(
    #             label="Resposta obtida!", state="complete", expanded=False
    #         )  
    #         st.write(f'**Resposta**: {st.session_state["resposta"]}')
            
    #     except Exception as e:
    #         status.update(
    #             label="Falha!", state="error", expanded=False
    #         ) 
    #         print(f'################# Erro ao retornar as perguntas da quest√£o {e}')
            
    
    
    
    
    
    
    # st.title('\n')
    # st.title('\n')
    # st.title('\n')
    # st.title('\n')
    # Carregar e exibir tabela de proposi√ß√µes
    df_proposicoes = pd.read_parquet("../data/proposicoes_deputados.parquet")
    st.dataframe(df_proposicoes)
    
    # Carregar e exibir resumo das proposi√ß√µes
    with open("../data/sumarizacao_proposicoes.json", "r", encoding="utf-8") as file:
        sumarizacao = json.load(file)
    
    st.subheader("Tema")
    st.write(sumarizacao["theme"])
    
    st.subheader("Resumo")
    st.write(sumarizacao["summary"])
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    st.divider()
    
    st.subheader("ü§ñ Assistente Virtual - C√¢mara dos Deputados")
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    
    if 'resposta' not in st.session_state:
        st.session_state['resposta'] = ''
    
    
        
    messages = st.container(height=300)
    
    parquet_path = '../data/df_informations.parquet'
    model_name = 'neuralmind/bert-base-portuguese-cased'
    # model_name = 'all-MiniLM-L6-v2'
    llm_model_dir = '../data/bertimbau/'
    k = 20 # n√∫mero de resultados mais pr√≥ximos
    candidate_count = 5 # n√∫mero de respostas geradas pelo Gemini Flash
    

    
    # question = st.selectbox('Escolha uma pergunta:', perguntas, index=0)   
    
    
    def atualizar_mensagens(messages):
        # Cont√™iner para exibir mensagens
        with messages:
            for message in st.session_state.messages:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])
    
    def gerar_resposta(prompt):
        import time
        time.sleep(2)
        return 'Voc√™ disse: '+ prompt
    
    if prompt := st.chat_input("Escreva sua pergunta:"):
        
        atualizar_mensagens(messages)
        
        with messages.chat_message("user"):
            st.markdown(prompt)
        
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        
        if 'index' not in st.session_state or 'texts' not in st.session_state or 'embedding_model' not in st.session_state:
            try:
                with st.status('Criando Base de dados...', expanded=True) as status:
                    texts, index, embedding_model = load_and_process_data(parquet_path, model_name, llm_model_dir)
                    st.session_state['texts'] = texts
                    st.session_state['index'] = index
                    st.session_state['embedding_model'] = embedding_model
                    status.update(
                    label="Base de Dados criada com sucesso!", state="complete", expanded=False
                )
            except Exception as e:
                print(f'################# Erro ao carregar e processar os dados {e}')
        else:
            texts = st.session_state['texts']
            index = st.session_state['index']
            embedding_model = st.session_state['embedding_model']
            st.toast("Index carregado com sucesso!")
        
        
        try:
            with st.status('Obtendo Resposta...', expanded=True) as status:
                questions, question_answers, response, responses, traducao = return_questions_from_one_question(prompt, texts, index, embedding_model, k, candidate_count)
                st.session_state.messages.append({"role": "assistant", "content": traducao})
                st.session_state['resposta'] = traducao 
                status.update(
                label="Resposta obtida!", state="complete", expanded=False
            )  
            # st.write(f'**Resposta**: {st.session_state["resposta"]}')
            
        except Exception as e:
            status.update(
                label="Falha!", state="error", expanded=False
            ) 
            print(f'################# Erro ao retornar as perguntas da quest√£o {e}')
            resposta_falha = 'Houve uma falha no processamento da pergunta. Por favor, tente novamente.' 
            st.session_state.messages.append({"role": "assistant", "content": resposta_falha})
            st.session_state['resposta'] = resposta_falha
        
        
        
        with messages.chat_message("assistant"):
            st.markdown(st.session_state['resposta'])
            
    
    
    with st.expander("Perguntas"):
        perguntas = ['Qual √© o partido pol√≠tico com mais deputados na c√¢mara?',
                    'Qual √© o deputado com mais despesas na c√¢mara?',
                    'Qual √© o tipo de despesa mais declarada pelos deputados da c√¢mara?',
                    'Quais s√£o as informa√ß√µes mais relevantes sobre as proposi√ß√µes que falam de Economia?',
                    "Quais s√£o as informa√ß√µes mais relevantes sobre as proposi√ß√µes que falam de 'Ci√™ncia, Tecnologia e Inova√ß√£o'?"
                    ]
        for p in perguntas:
            st.code(p)
    with st.expander("Informa√ß√µes"):
        st.write("As informa√ß√µes submetidas ao embbeding model foram as seguintes:")
        df_information = pd.read_parquet('../data/df_informations.parquet')
        for x, info in enumerate(df_information['information']):
            # usa markdow para escrever um text com h3
            st.markdown(f'<h3 style="color:blue;">{x+1}</h3>{info}'+f'{info}', unsafe_allow_html=True)